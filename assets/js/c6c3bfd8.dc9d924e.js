"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5019],{9989:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var o=n(5893),i=n(1151);const a={},s="Ecosystem",l={id:"Ecosystem",title:"Ecosystem",description:"This page lists libraries that have integrations with Autogen for LLM applications using multiple agents in alphabetical order. Including your own integration to this list is highly encouraged. Simply open a pull request with a few lines of text, see the dropdown below for more information.",source:"@site/docs/Ecosystem.md",sourceDirName:".",slug:"/Ecosystem",permalink:"/autogen/docs/Ecosystem",draft:!1,unlisted:!1,editUrl:"https://github.com/microsoft/autogen/edit/main/website/docs/Ecosystem.md",tags:[],version:"current",frontMatter:{}},r={},c=[{value:"MemGPT + AutoGen",id:"memgpt--autogen",level:2},{value:"Microsoft Fabric + AutoGen",id:"microsoft-fabric--autogen",level:2},{value:"Ollama + AutoGen",id:"ollama--autogen",level:2}];function m(e){const t={a:"a",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",ul:"ul",...(0,i.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"ecosystem",children:"Ecosystem"}),"\n",(0,o.jsx)(t.p,{children:"This page lists libraries that have integrations with Autogen for LLM applications using multiple agents in alphabetical order. Including your own integration to this list is highly encouraged. Simply open a pull request with a few lines of text, see the dropdown below for more information."}),"\n",(0,o.jsx)(t.h2,{id:"memgpt--autogen",children:"MemGPT + AutoGen"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"MemGPT Example",src:n(9378).Z+"",width:"256",height:"254"})}),"\n",(0,o.jsx)(t.p,{children:"MemGPT enables LLMs to manage their own memory and overcome limited context windows. You can use MemGPT to create perpetual chatbots that learn about you and modify their own personalities over time. You can connect MemGPT to your own local filesystems and databases, as well as connect MemGPT to your own tools and APIs. The MemGPT + AutoGen integration allows you to equip any AutoGen agent with MemGPT capabilities."}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"https://memgpt.readme.io/docs/autogen",children:"MemGPT + AutoGen Documentation with Code Examples"})}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"microsoft-fabric--autogen",children:"Microsoft Fabric + AutoGen"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Fabric Example",src:n(6427).Z+"",width:"2085",height:"1151"})}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.a,{href:"https://learn.microsoft.com/en-us/fabric/get-started/microsoft-fabric-overview",children:"Microsoft Fabric"})," is an all-in-one analytics solution for enterprises that covers everything from data movement to data science, Real-Time Analytics, and business intelligence. It offers a comprehensive suite of services, including data lake, data engineering, and data integration, all in one place. In this notenook, we give a simple example for using AutoGen in Microsoft Fabric."]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"https://github.com/microsoft/autogen/blob/main/notebook/agentchat_microsoft_fabric.ipynb",children:"Microsoft Fabric + AutoGen Code Examples"})}),"\n"]}),"\n",(0,o.jsx)(t.h2,{id:"ollama--autogen",children:"Ollama + AutoGen"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Ollama Example",src:n(6730).Z+"",width:"234",height:"204"})}),"\n",(0,o.jsxs)(t.p,{children:[(0,o.jsx)(t.a,{href:"https://ollama.com/",children:"Ollama"})," allows the users to run open-source large language models, such as Llama 2, locally. Ollama bundles model weights, configuration, and data into a single package, defined by a Modelfile. It optimizes setup and configuration details, including GPU usage."]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"https://ollama.ai/blog/openai-compatibility",children:"Ollama + AutoGen instruction"})}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}},6427:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/ecosystem-fabric-eee936fd890a030ea63d6cd6f1528afa.png"},9378:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/ecosystem-memgpt-db7e37eac957d8d744aeaaef8534b7d9.png"},6730:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/ecosystem-ollama-712f5198953f7219914be6b50a850b82.png"},1151:(e,t,n)=>{n.d(t,{Z:()=>l,a:()=>s});var o=n(7294);const i={},a=o.createContext(i);function s(e){const t=o.useContext(a);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(a.Provider,{value:t},e.children)}}}]);