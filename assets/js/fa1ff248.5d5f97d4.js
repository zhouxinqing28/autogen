"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[133],{74482:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var s=n(85893),a=n(11151);const o={title:"StateFlow - Build LLM Workflows with Customized State-Oriented Transition Function in GroupChat",authors:"yiranwu",tags:["LLM","research"]},i=void 0,r={permalink:"/autogen/blog/2024/02/29/StateFlow",source:"@site/blog/2024-02-29-StateFlow/index.mdx",title:"StateFlow - Build LLM Workflows with Customized State-Oriented Transition Function in GroupChat",description:"TL;DR:: Introduce Stateflow, a task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines.",date:"2024-02-29T00:00:00.000Z",formattedDate:"February 29, 2024",tags:[{label:"LLM",permalink:"/autogen/blog/tags/llm"},{label:"research",permalink:"/autogen/blog/tags/research"}],readingTime:6.39,hasTruncateMarker:!1,authors:[{name:"Yiran Wu",title:"PhD student at Pennsylvania State University",url:"https://github.com/kevin666aa",imageURL:"https://github.com/kevin666aa.png",key:"yiranwu"}],frontMatter:{title:"StateFlow - Build LLM Workflows with Customized State-Oriented Transition Function in GroupChat",authors:"yiranwu",tags:["LLM","research"]},unlisted:!1,prevItem:{title:"What's New in AutoGen?",permalink:"/autogen/blog/2024/03/03/AutoGen-Update"},nextItem:{title:"FSM Group Chat -- User-specified agent transitions",permalink:"/autogen/blog/2024/02/11/FSM-GroupChat"}},c={authorsImageUrls:[void 0]},l=[{value:"Introduction",id:"introduction",level:2},{value:"StateFlow",id:"stateflow",level:2},{value:"Experiments",id:"experiments",level:2},{value:"Implement StateFlow With GroupChat",id:"implement-stateflow-with-groupchat",level:2},{value:"For Further Reading",id:"for-further-reading",level:2}];function h(e){const t={a:"a",code:"code",em:"em",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"TL;DR:"}),": Introduce Stateflow, a task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines.\nIntroduce how to use GroupChat to realize such an idea with a customized speaker selection function."]}),"\n",(0,s.jsx)(t.p,{children:"The paper is coming soon!"}),"\n",(0,s.jsx)(t.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsxs)(t.p,{children:["LLMs have increasingly been employed to solve complex, multi-step tasks, e.g., tasks that require a sequence of complex reasoning\nand interacting with external environments and tools. To facilitate the development of such applications, we introduce ",(0,s.jsx)(t.strong,{children:"StateFlow"}),", a new paradigm\nthat conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of\nstate transitions, we can ground the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process."]}),"\n",(0,s.jsx)(t.h2,{id:"stateflow",children:"StateFlow"}),"\n",(0,s.jsxs)(t.p,{children:["Finite State machines (FSMs) are used as control systems to monitor practical applications, such as traffic light control.\nA defined state machine is a model of behavior that decides what to do based on current status. A state represents one situation that the state machine might be in, and all states cover all possible situations of the FSM.\nDrawing from this concept, we want to use state machines to model the task-solving process of LLMs. When using an LLM to solve a task, each step of the task-solving process can be mapped to a state.\nFor example, the process starts at the ",(0,s.jsx)(t.em,{children:"Init"})," state when the task is given. When reaching a state, a sequence of output functions is called to add content to the context history, including sending a specific instruction, using a tool, or calling the LLM itself.\nBased on the current state and context history, the ",(0,s.jsx)(t.strong,{children:"StateFlow"})," model determines the next state to transit to. The task-solving process progresses by transitioning through different states and performing corresponding actions and ends until a final state is reached.\nEssentially, we are sending different instructions to an LLM to ask it to perform different actions based on its current status."]}),"\n",(0,s.jsxs)(t.p,{children:["In ",(0,s.jsx)(t.strong,{children:"StateFlow"}),", we construct a state machine to control a single LLM, sending different instructions to it at different states.\nWe also provide an agent view of our framework, ",(0,s.jsx)(t.strong,{children:"SF_Agent"}),", that can use different LLM agents to perform actions at different states.\nIn this case, we don't need to add instructions to the context history and call the LLM. Instead, we construct individual agents with pre-set instructions and (potentially) different LLMs.\nAutoGen is the perfect platform to implement ",(0,s.jsx)(t.strong,{children:"SF_Agent"}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"experiments",children:"Experiments"}),"\n",(0,s.jsxs)(t.p,{children:["We evaluate ",(0,s.jsx)(t.strong,{children:"StateFlow"})," on the SQL task and Bash task from the InterCode benchmark, with both GPT-3.5-Turbo and GPT-4.\nWe construct different ",(0,s.jsx)(t.strong,{children:"StateFlow"})," models for each task (See the figure below). But note that most of the states are shared between the two tasks.\nWithin each state, we define a sequence of actions to be performed. The most common action sequence is P->M->E, meaning we first send a prompt, then call the LLM to generate a response, and finally execute commands from the response.\n",(0,s.jsx)(t.img,{alt:"Intercode Example",src:n(51779).Z+"",width:"1424",height:"874"})]}),"\n",(0,s.jsx)(t.p,{children:"We record different metrics for a comprehensive comparison. The 'SR' (success rate) and 'rewards' measure the performance,\n'Turns represents a number of interactions with the environment, and 'Error Rate' represents the percentage of errors of the commands executed.\nWe also record the cost and token counts to show the LLM usage."}),"\n",(0,s.jsx)(t.p,{children:"We compare with the following baselines:\n(1) ReAct: a few-shot prompting method that prompts the model to generate thoughts and actions.\n(2) Plan & Solve: A two-step prompting strategy to first ask the model to propose a plan and then execute it."}),"\n",(0,s.jsx)(t.p,{children:"We show the results of the Bash task in the figure below:"}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"Bash Result",src:n(6361).Z+"",width:"1430",height:"600"})}),"\n",(0,s.jsxs)(t.p,{children:["Our evaluation demonstrates the advantages of ",(0,s.jsx)(t.strong,{children:"StateFlow"})," and ",(0,s.jsx)(t.strong,{children:"SF_Agent"})," over existing methods in terms of both effectiveness and efficiency.\nFor example, in the Bash task with GPT-4, ",(0,s.jsx)(t.strong,{children:"SF_Agent"})," improves the success rate by 8% and has 4x less cost compared to ReAct prompting."]}),"\n",(0,s.jsx)(t.h2,{id:"implement-stateflow-with-groupchat",children:"Implement StateFlow With GroupChat"}),"\n",(0,s.jsxs)(t.p,{children:["We illustrate how to build ",(0,s.jsx)(t.strong,{children:"StateFlow"})," with GroupChat. Previous blog ",(0,s.jsx)(t.a,{href:"/blog/2024/02/11/FSM-GroupChat/",children:"FSM Group Chat"}),"\nintroduces a new feature of GroupChat that allows us to input a transition graph to constrain agent transitions.\nIt requires us to use natural language to describe the transition conditions of the FSM in the agent's ",(0,s.jsx)(t.code,{children:"description"})," parameter, and then use an LLM to take in the description and make decisions of the next agent.\nIn this blog, we take advantages of a customized speaker selection function passed to the ",(0,s.jsx)(t.code,{children:"speaker_selection_method"})," of the ",(0,s.jsx)(t.code,{children:"GroupChat"})," object.\nThis function allows us to custom the transition logic between agents, and can be used together with the transition graph introduced in FSM Group Chat. The current StateFlow implementation also allows the user to override the transition graph.\nThese transitions can be based on the current speaker and static checking of the context history (for example, checking if 'Error' is in the last message)."]}),"\n",(0,s.jsxs)(t.p,{children:["We present an example of how to build a state-oriented workflow using GroupChat.\nWe define a custom speaker selection function to be passed into the ",(0,s.jsx)(t.code,{children:"speaker_selection_method"})," parameter of the GroupChat.\nHere, the task is to retrieve research papers related to a given topic, and create a markdown table for these papers."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{alt:"StateFlow Example",src:n(70886).Z+"",width:"1226",height:"472"})}),"\n",(0,s.jsx)(t.p,{children:"We define the following agents:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Initializer: Start the workflow by sending a task."}),"\n",(0,s.jsx)(t.li,{children:"Coder: Retrieve papers from the internet by writing code."}),"\n",(0,s.jsx)(t.li,{children:"Executor: Execute the code."}),"\n",(0,s.jsx)(t.li,{children:"Scientist: Read the papers and write a summary."}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# Define the agents, the code is for illustration purposes and is not executable.\ninitializer = autogen.UserProxyAgent(\n   name="Init"\n)\ncoder = autogen.AssistantAgent(\n   name="Coder",\n   system_message="""You are the Coder. Write Python Code to retrieve papers from arxiv."""\n)\nexecutor = autogen.UserProxyAgent(\n   name="Executor",\n   system_message="Executor. Execute the code written by the Coder and report the result.",\n)\nscientist = autogen.AssistantAgent(\n   name="Scientist",\n   system_message="""You are the Scientist. Please categorize papers after seeing their abstracts printed and create a markdown table with Domain, Title, Authors, Summary and Link. Return \'TERMINATE\' in the end.""",\n)\n'})}),"\n",(0,s.jsx)(t.p,{children:"In the Figure, we define a simple workflow for research with 4 states: Init, Retrieve, Reserach and End. Within each state, we will call different agents to perform the tasks."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Init: We use the initializer to start the workflow."}),"\n",(0,s.jsx)(t.li,{children:"Retrieve: We will first call the coder to write code and then call the executor to execute the code."}),"\n",(0,s.jsx)(t.li,{children:"Research: We will call the scientist to read the papers and write a summary."}),"\n",(0,s.jsx)(t.li,{children:"End: We will end the workflow."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Then we define a customized function to control the transition between states:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'def state_transition(last_speaker, groupchat):\n   messages = groupchat.messages\n\n   if last_speaker is initializer:\n       # init -> retrieve\n       return coder\n   elif last_speaker is coder:\n       # retrieve: action 1 -> action 2\n       return executor\n   elif last_speaker is executor:\n       if messages[-1]["content"] == "exitcode: 1":\n           # retrieve --(execution failed)--\x3e retrieve\n           return coder\n       else:\n           # retrieve --(execution success)--\x3e research\n           return scientist\n   elif last_speaker == "Scientist":\n       # research -> end\n       return None\n\n\ngroupchat = autogen.GroupChat(\n   agents=[initializer, coder, executor, scientist],\n   messages=[],\n   max_round=20,\n   speaker_selection_method=state_transition,\n)\n'})}),"\n",(0,s.jsxs)(t.p,{children:["We recommend implementing the transition logic for each speaker in the customized function. In analogy to a state machine, a state transition function determines the next state based on the current state and input.\nInstead of returning an ",(0,s.jsx)(t.code,{children:"Agent"})," class representing the next speaker, we can also return a string from ",(0,s.jsx)(t.code,{children:"['auto', 'manual', 'random', 'round_robin']"})," to select a default method to use.\nFor example, we can always default to the built-in ",(0,s.jsx)(t.code,{children:"auto"})," method to employ a LLM-based group chat manager to select the next speaker.\nWhen returning ",(0,s.jsx)(t.code,{children:"None"}),', the group chat will terminate. Note that some of the transitions, such as "initializer" -> "coder" can be defined with the transition graph.']}),"\n",(0,s.jsx)(t.h2,{id:"for-further-reading",children:"For Further Reading"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/docs/notebooks/agentchat_groupchat_stateflow",children:"StateFlow notebook"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/docs/notebooks/agentchat_groupchat_customized",children:"GroupChat with Customized Speaker Selection notebook"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsx)(t.a,{href:"/blog/2024/02/11/FSM-GroupChat/",children:"FSM Group Chat"})}),"\n",(0,s.jsx)(t.li,{children:(0,s.jsxs)(t.a,{href:"/docs/Getting-Started",children:["Documentation about ",(0,s.jsx)(t.code,{children:"autogen"})]})}),"\n"]})]})}function d(e={}){const{wrapper:t}={...(0,a.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},6361:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/bash_result-f93ebfe76d6d837e614ae1a3ebc06274.png"},51779:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/intercode-519533781527d1fcca99dd8b5b0d90b2.png"},70886:(e,t,n)=>{n.d(t,{Z:()=>s});const s=n.p+"assets/images/sf_example_1-4e72bff416bab1de6a634bdcc552c199.png"},11151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>i});var s=n(67294);const a={},o=s.createContext(a);function i(e){const t=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);