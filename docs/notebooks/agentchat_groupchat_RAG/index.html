<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-notebooks/agentchat_groupchat_RAG" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Group Chat with Retrieval Augmented Generation | AutoGen</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_RAG"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Group Chat with Retrieval Augmented Generation | AutoGen"><meta data-rh="true" name="description" content="Implement and manage a multi-agent chat system using AutoGen, where AI assistants retrieve information, generate code, and interact collaboratively to solve complex tasks, especially in areas not covered by their training data."><meta data-rh="true" property="og:description" content="Implement and manage a multi-agent chat system using AutoGen, where AI assistants retrieve information, generate code, and interact collaboratively to solve complex tasks, especially in areas not covered by their training data."><link data-rh="true" rel="icon" href="/autogen/img/ag.ico"><link data-rh="true" rel="canonical" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_RAG"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_RAG" hreflang="en"><link data-rh="true" rel="alternate" href="https://microsoft.github.io/autogen/docs/notebooks/agentchat_groupchat_RAG" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/autogen/blog/rss.xml" title="AutoGen RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/autogen/blog/atom.xml" title="AutoGen Atom Feed">






<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
<script src="/autogen/js/custom.js" async defer="defer"></script><link rel="stylesheet" href="/autogen/assets/css/styles.d8ef5d37.css">
<script src="/autogen/assets/js/runtime~main.f6c7c06d.js" defer="defer"></script>
<script src="/autogen/assets/js/main.887e557c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const a=new URLSearchParams(window.location.search).entries();for(var[t,e]of a)if(t.startsWith("docusaurus-data-")){var n=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(n,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#fafbfc;color:#091E42" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">What's new in AutoGen? Read <a href="/autogen/blog/2024/03/03/AutoGen-Update">this blog</a> for an overview of updates</div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/autogen/"><div class="navbar__logo"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/autogen/img/ag.svg" alt="AutoGen" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AutoGen</b></a><a class="navbar__item navbar__link" href="/autogen/docs/Getting-Started">Docs</a><a class="navbar__item navbar__link" href="/autogen/docs/reference/agentchat/conversable_agent">API</a><a class="navbar__item navbar__link" href="/autogen/blog">Blog</a><a class="navbar__item navbar__link" href="/autogen/docs/FAQ">FAQ</a><a class="navbar__item navbar__link" href="/autogen/docs/Examples">Examples</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/autogen/docs/notebooks">Notebooks</a><a class="navbar__item navbar__link" href="/autogen/docs/Gallery">Gallery</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Other Languages</a><ul class="dropdown__menu"><li><a href="https://microsoft.github.io/autogen-for-net/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Dotnet<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><a href="https://github.com/microsoft/autogen" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div><div class="searchHintContainer_Pkmr"><kbd class="searchHint_iIMx">ctrl</kbd><kbd class="searchHint_iIMx">K</kbd></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/autogen/docs/notebooks">Notebooks</a><button aria-label="Collapse sidebar category &#x27;Notebooks&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_RetrieveChat">Using RetrieveChat for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_auto_feedback_from_code_execution">Task Solving with Code Generation, Execution and Debugging</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_capability_long_context_handling">Handling A Long Context via `TransformChatHistory`</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_compression">Conversations with Chat History Compression Enabled</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_custom_model">Agent Chat with custom model loading</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_function_call_async">Task Solving with Provided Tools as Functions (Asynchronous Function Calls)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat">Group Chat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_RAG">Group Chat with Retrieval Augmented Generation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_customized">Group Chat with Customized Speaker Selection Method</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_finite_state_machine">FSM - User can input speaker transition constraints</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_research">Perform Research with Multi-Agent Group Chat</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_stateflow">StateFlow: Build Workflows through State-Oriented Actions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_groupchat_vis">Group Chat with Coder and Visualization Critic</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_image_generation_capability">Adding Different LLM Modalities to Exisiting Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_lmm_gpt-4v">Engaging with Multimodal Models: GPT-4V in AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_logging">Runtime Logging with AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_multi_task_async_chats">Solving Multiple Tasks in a Sequence of Async Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_multi_task_chats">Solving Multiple Tasks in a Sequence of Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nested_chats_chess">Nested Chats for Tool Use in Conversational Chess</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nested_sequential_chats">Solving Complex Tasks with A Sequence of Nested Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nestedchat">Solving Complex Tasks with Nested Chats</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_nestedchat_optiguide">OptiGuide with Nested Chats in AutoGen</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_qdrant_RetrieveChat">Using RetrieveChat with Qdrant for Retrieve Augmented Code Generation and Question Answering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_society_of_mind">SocietyOfMindAgent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_teachability">Chatting with a teachable agent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_teaching">Auto Generated Agent Chat: Teaching</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchat_video_transcript_translate_with_whisper">Translating Video audio using Whisper and GPT-3.5-turbo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/autogen/docs/notebooks/agentchats_sequential_chats">Solving Multiple Tasks in a Sequence of Chats with Different Conversable Agent Pairs</a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/autogen/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/autogen/docs/notebooks"><span itemprop="name">Notebooks</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Group Chat with Retrieval Augmented Generation</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Group Chat with Retrieval Augmented Generation</h1>
<p><a href="https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" class="img_ev3q"></a>
<a href="https://github.com/microsoft/autogen/blob/main/notebook/agentchat_groupchat_RAG.ipynb" target="_blank" rel="noopener noreferrer"><img decoding="async" loading="lazy" src="https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github" alt="Open on GitHub" class="img_ev3q"></a></p>
<p>AutoGen supports conversable agents powered by LLMs, tools, or humans,
performing tasks collectively via automated chat. This framework allows
tool use and human participation through multi-agent conversation.
Please find documentation about this feature
<a href="https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat" target="_blank" rel="noopener noreferrer">here</a>.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Requirements</div><div class="admonitionContent_BuS1"><p>Some extra dependencies are needed for this notebook, which can be installed via pip:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">pip install pyautogen[retrievechat]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For more information, please refer to the <a href="/autogen/docs/installation/">installation guide</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="set-your-api-endpoint">Set your API Endpoint<a href="#set-your-api-endpoint" class="hash-link" aria-label="Direct link to Set your API Endpoint" title="Direct link to Set your API Endpoint">​</a></h2>
<p>The
<a href="https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json" target="_blank" rel="noopener noreferrer"><code>config_list_from_json</code></a>
function loads a list of configurations from an environment variable or
a json file.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> typing_extensions </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> Annotated</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> chromadb</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> autogen</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> AssistantAgent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">from</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">agentchat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">contrib</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">retrieve_user_proxy_agent </span><span class="token keyword" style="font-style:italic">import</span><span class="token plain"> RetrieveUserProxyAgent</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">config_list </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">config_list_from_json</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;OAI_CONFIG_LIST&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">print</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;LLM models: &quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">i</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> i </span><span class="token keyword" style="font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">range</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token builtin" style="color:rgb(130, 170, 255)">len</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">LLM models:  [&#x27;gpt-4-1106-preview&#x27;, &#x27;gpt-4-turbo-preview&#x27;, &#x27;gpt-4-0613&#x27;, &#x27;gpt-35-turbo-0613&#x27;, &#x27;gpt-35-turbo-1106&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Learn more about configuring LLMs for agents <a href="/autogen/docs/topics/llm_configuration">here</a>.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="construct-agents">Construct Agents<a href="#construct-agents" class="hash-link" aria-label="Direct link to Construct Agents" title="Direct link to Construct Agents">​</a></h2>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">llm_config </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;timeout&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">60</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;temperature&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">0</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;config_list&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">return</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">isinstance</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">dict</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">and</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;TERMINATE&quot;</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">==</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">x</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">get</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token number" style="color:rgb(247, 140, 108)">9</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">upper</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">boss </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">UserProxyAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Boss&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    is_termination_msg</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    human_input_mode</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;NEVER&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    code_execution_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token boolean" style="color:rgb(255, 88, 116)">False</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># we don&#x27;t want to execute code in this case.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    default_auto_reply</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Reply `TERMINATE` if the task is done.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;The boss who ask questions and give tasks.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">boss_aid </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> RetrieveUserProxyAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Boss_Assistant&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    is_termination_msg</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    human_input_mode</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;NEVER&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    max_consecutive_auto_reply</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">3</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    retrieve_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;task&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;code&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;docs_path&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;https://raw.githubusercontent.com/microsoft/FLAML/main/website/docs/Examples/Integrate%20-%20Spark.md&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;chunk_token_size&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">1000</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> config_list</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token number" style="color:rgb(247, 140, 108)">0</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;model&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;client&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> chromadb</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">PersistentClient</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">path</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;/tmp/chromadb&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;collection_name&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;groupchat&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;get_or_create&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> </span><span class="token boolean" style="color:rgb(255, 88, 116)">True</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    code_execution_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token boolean" style="color:rgb(255, 88, 116)">False</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># we don&#x27;t want to execute code in this case.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Assistant who has extra content retrieval power for solving difficult problems.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">coder </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Senior_Python_Engineer&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    is_termination_msg</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;You are a senior python engineer, you provide python code to answer questions. Reply `TERMINATE` in the end when everything is done.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Senior Python Engineer who can write code to solve problems and answer questions.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">pm </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Product_Manager&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    is_termination_msg</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;You are a product manager. Reply `TERMINATE` in the end when everything is done.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Product Manager who can design and plan the project.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">reviewer </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">AssistantAgent</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    name</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Code_Reviewer&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    is_termination_msg</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">termination_msg</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    system_message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;You are a code reviewer. Reply `TERMINATE` in the end when everything is done.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Code Reviewer who can review the code.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">PROBLEM </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;How to use spark for parallel training in FLAML? Give me sample code.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">_reset_agents</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    coder</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    reviewer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">rag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _reset_agents</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    groupchat </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        agents</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> coder</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> reviewer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> messages</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> max_round</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">12</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> speaker_selection_method</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;round_robin&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    manager </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChatManager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">groupchat</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">groupchat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Start chatting with boss_aid as this is the user proxy agent.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        manager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">message_generator</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        problem</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">PROBLEM</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        n_results</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">3</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">norag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _reset_agents</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    groupchat </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        agents</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> coder</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> reviewer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        messages</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        max_round</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">12</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        speaker_selection_method</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;auto&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        allow_repeat_speaker</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token boolean" style="color:rgb(255, 88, 116)">False</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    manager </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChatManager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">groupchat</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">groupchat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Start chatting with the boss as this is the user proxy agent.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        manager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">PROBLEM</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">call_rag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    _reset_agents</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># In this case, we will have multiple user proxy agents and we don&#x27;t initiate the chat</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># with RAG user proxy agent.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># In order to use RAG user proxy agent, we need to wrap RAG agents in a function and call</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># it from other agents.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(130, 170, 255)">retrieve_content</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        message</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> Annotated</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Refined message which keeps the original meaning and can be used to retrieve content for code generation and question answering.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        n_results</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> Annotated</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token builtin" style="color:rgb(130, 170, 255)">int</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;number of results&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token number" style="color:rgb(247, 140, 108)">3</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token operator" style="color:rgb(137, 221, 255)">-</span><span class="token operator" style="color:rgb(137, 221, 255)">&gt;</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">str</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">n_results </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> n_results  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Set the number of results to be retrieved.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Check if we need to update the context.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        update_context_case1</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> update_context_case2 </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">_check_update_context</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">message</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token keyword" style="font-style:italic">if</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">update_context_case1 </span><span class="token keyword" style="font-style:italic">or</span><span class="token plain"> update_context_case2</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">and</span><span class="token plain"> boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">update_context</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">problem </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> message </span><span class="token keyword" style="font-style:italic">if</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">not</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(130, 170, 255)">hasattr</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;problem&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"> </span><span class="token keyword" style="font-style:italic">else</span><span class="token plain"> boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">problem</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            _</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> ret_msg </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">_generate_retrieve_user_reply</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">message</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token keyword" style="font-style:italic">else</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            _context </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;problem&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> message</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;n_results&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"> n_results</span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            ret_msg </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">message_generator</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> </span><span class="token boolean" style="color:rgb(255, 88, 116)">None</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> _context</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token keyword" style="font-style:italic">return</span><span class="token plain"> ret_msg </span><span class="token keyword" style="font-style:italic">if</span><span class="token plain"> ret_msg </span><span class="token keyword" style="font-style:italic">else</span><span class="token plain"> message</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss_aid</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">human_input_mode </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(195, 232, 141)">&quot;NEVER&quot;</span><span class="token plain">  </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Disable human input for boss_aid since it only retrieves content.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> caller </span><span class="token keyword" style="font-style:italic">in</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> coder</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> reviewer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        d_retrieve_content </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> caller</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">register_for_llm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">            description</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;retrieve content for code generation and question answering.&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> api_style</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;function&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">retrieve_content</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token keyword" style="font-style:italic">for</span><span class="token plain"> executor </span><span class="token keyword" style="font-style:italic">in</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        executor</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">register_for_execution</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">d_retrieve_content</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    groupchat </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        agents</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token plain">boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> pm</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> coder</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> reviewer</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        messages</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        max_round</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token number" style="color:rgb(247, 140, 108)">12</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        speaker_selection_method</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;round_robin&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        allow_repeat_speaker</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token boolean" style="color:rgb(255, 88, 116)">False</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    manager </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> autogen</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">GroupChatManager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">groupchat</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">groupchat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"> llm_config</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">llm_config</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># Start chatting with the boss as this is the user proxy agent.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    boss</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token plain">initiate_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        manager</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">        message</span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain">PROBLEM</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="start-chat">Start Chat<a href="#start-chat" class="hash-link" aria-label="Direct link to Start Chat" title="Direct link to Start Chat">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="userproxyagent-doesnt-get-the-correct-code">UserProxyAgent doesn’t get the correct code<a href="#userproxyagent-doesnt-get-the-correct-code" class="hash-link" aria-label="Direct link to UserProxyAgent doesn’t get the correct code" title="Direct link to UserProxyAgent doesn’t get the correct code">​</a></h3>
<p><a href="https://github.com/microsoft/FLAML" target="_blank" rel="noopener noreferrer">FLAML</a> was open sourced in 2020, so
ChatGPT is familiar with it. However, Spark-related APIs were added in
2022, so they were not in ChatGPT’s training data. As a result, we end
up with invalid code.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">norag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Boss</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">How to use spark for parallel training in FLAML? Give me sample code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Senior_Python_Engineer</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Apache Spark for parallel training in FLAML, you need to use the `flaml.tune.run` function. Here is a sample code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml import tune</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Define your training function</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">def training_function(config):</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    # your training code here</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    pass</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Define your search space</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">search_space = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;lr&quot;: tune.loguniform(1e-4, 1e-1),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;momentum&quot;: tune.uniform(0.1, 0.9),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Use SparkTrials for parallelization</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from ray.tune import SparkTrials</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">spark_trials = SparkTrials(parallelism=2)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">analysis = tune.run(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    training_function,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    config=search_space,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    num_samples=10,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    scheduler=tune.schedulers.FIFOScheduler(),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    progress_reporter=tune.JupyterNotebookReporter(overwrite=True),</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    trial_executor=spark_trials,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Best config: &quot;, analysis.get_best_config(metric=&quot;accuracy&quot;, mode=&quot;max&quot;))</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Get a dataframe for analyzing trial results.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">df = analysis.results_df</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">In this code, `training_function` is your training function, which should take a `config` argument. This `config` argument is a dictionary that includes hyperparameters for your model. The `search_space` is a dictionary that defines the search space for your hyperparameters.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">The `tune.run` function is used to start the hyperparameter tuning. The `config` argument is your search space, `num_samples` is the number of times to sample from the search space, and `scheduler` is the scheduler for the trials. The `trial_executor` argument is set to `spark_trials` to use Spark for parallelization.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">The `analysis.get_best_config` function is used to get the best hyperparameters found during the tuning. The `analysis.results_df` gives a dataframe that contains the results of all trials.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that you need to have Apache Spark and Ray installed and properly configured in your environment to run this code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token builtin" style="color:rgb(130, 170, 255)">TERMINATE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="retrieveuserproxyagent-get-the-correct-code">RetrieveUserProxyAgent get the correct code<a href="#retrieveuserproxyagent-get-the-correct-code" class="hash-link" aria-label="Direct link to RetrieveUserProxyAgent get the correct code" title="Direct link to RetrieveUserProxyAgent get the correct code">​</a></h3>
<p>Since RetrieveUserProxyAgent can perform retrieval-augmented generation
based on the given documentation file, ChatGPT can generate the correct
code for us!</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">rag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic"># type exit to terminate the chat</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">doc_ids:  [[&#x27;doc_0&#x27;, &#x27;doc_1&#x27;, &#x27;doc_122&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_0 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_1 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_122 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Boss_Assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: How to use spark for parallel training in FLAML? Give me sample code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: # Integrate - Spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML has integrated Spark for distributed training. There are two main aspects of integration with Spark:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- Use Spark ML estimators for AutoML.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- Use Spark to run training in parallel spark jobs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Spark ML Estimators</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML integrates estimators based on Spark ML models. These models are trained in parallel using Spark, so we called them Spark estimators. To use these models, you first need to organize your data in the required format.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">### Data</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For Spark estimators, AutoML only consumes Spark data. FLAML provides a convenient function `to_pandas_on_spark` in the `flaml.automl.spark.utils` module to convert your data into a pandas-on-spark (`pyspark.pandas`) dataframe/series, which Spark estimators require.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This utility function takes data in the form of a `pandas.Dataframe` or `pyspark.sql.Dataframe` and converts it into a pandas-on-spark dataframe. It also takes `pandas.Series` or `pyspark.sql.Dataframe` and converts it into a [pandas-on-spark](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html) series. If you pass in a `pyspark.pandas.Dataframe`, it will not make any changes.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This function also accepts optional arguments `index_col` and `default_index_type`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `index_col` is the column name to use as the index, default is None.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `default_index_type` is the default index type, default is &quot;distributed-sequence&quot;. More info about default index type could be found on Spark official [documentation](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/options.html#default-index-type)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example code snippet for Spark Data:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a dictionary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {&quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a pandas DataFrame</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert to pandas-on-spark dataframe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Spark ML models you need to format your data appropriately. Specifically, use [`VectorAssembler`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html) to merge all feature columns into a single vector column.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example of how to use it:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from pyspark.ml.feature import VectorAssembler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">columns = psdf.columns</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">feature_cols = [col for col in columns if col != label]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">featurizer = VectorAssembler(inputCols=feature_cols, outputCol=&quot;features&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = featurizer.transform(psdf.to_spark(index_col=&quot;index&quot;))[&quot;index&quot;, &quot;features&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Later in conducting the experiment, use your pandas-on-spark data like non-spark data and pass them using `X_train, y_train` or `dataframe, label`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">### Estimators</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#### Model List</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `lgbm_spark`: The class for fine-tuning Spark version LightGBM models, using [SynapseML](https://microsoft.github.io/SynapseML/docs/features/lightgbm/about/) API.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#### Usage</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">First, prepare your data in the required format as described in the previous section.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">By including the models you intend to try in the `estimators_list` argument to `flaml.automl`, FLAML will start trying configurations for these models. If your input is Spark data, FLAML will also use estimators with the `_spark` postfix by default, even if you haven&#x27;t specified them.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example code snippet using SparkML models in AutoML:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># prepare your data in pandas-on-spark format as we previously mentioned</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],  # this setting is optional</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Parallel Spark Jobs</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You can activate Spark as the parallel backend during parallel tuning in both [AutoML](/docs/Use-Cases/Task-Oriented-AutoML#parallel-tuning) and [Hyperparameter Tuning](/docs/Use-Cases/Tune-User-Defined-Function#parallel-tuning), by setting the `use_spark` to `true`. FLAML will dispatch your job to the distributed Spark backend using [`joblib-spark`](https://github.com/joblib/joblib-spark).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that you should not set `use_spark` to `true` when applying AutoML and Tuning for Spark Data. This is because only SparkML models will be used for Spark Data in AutoML and Tuning. As SparkML models run in parallel, there is no need to distribute them with `use_spark` again.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">All the Spark-related arguments are stated below. These arguments are available in both Hyperparameter Tuning and AutoML:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `use_spark`: boolean, default=False | Whether to use spark to run the training in parallel spark jobs. This can be used to accelerate training on large models and large datasets, but will incur more overhead in time and thus slow down training in some cases. GPU training is not supported yet when use_spark is True. For Spark clusters, by default, we will launch one trial per executor. However, sometimes we want to launch more trials than the number of executors (e.g., local mode). In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override the detected `num_executors`. The final number of concurrent trials will be the minimum of `n_concurrent_trials` and `num_executors`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `n_concurrent_trials`: int, default=1 | The number of concurrent trials. When n_concurrent_trials &gt; 1, FLAML performes parallel tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `force_cancel`: boolean, default=False | Whether to forcely cancel Spark jobs if the search time exceeded the time budget. Spark jobs include parallel tuning jobs and Spark-based model training jobs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">An example code snippet for using parallel Spark jobs:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_experiment = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;n_concurrent_trials&quot;: 2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;use_spark&quot;: True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;force_cancel&quot;: True, # Activating the force_cancel option can immediately halt Spark jobs once they exceed the allocated time_budget.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=dataframe,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **automl_settings,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2684,4/26/2011,2,0,4,17,0,2,1,1,0.68,0.6364,0.61,0.3582,521</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2685,4/26/2011,2,0,4,18,0,2,1,1,0.68,0.6364,0.65,0.4478,528</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2686,4/26/2011,2,0,4,19,0,2,1,1,0.64,0.6061,0.73,0.4179,328</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2687,4/26/2011,2,0,4,20,0,2,1,1,0.64,0.6061,0.73,0.3582,234</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2688,4/26/2011,2,0,4,21,0,2,1,1,0.62,0.5909,0.78,0.2836,195</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2689,4/26/2011,2,0,4,22,0,2,1,2,0.6,0.5606,0.83,0.194,148</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2690,4/26/2011,2,0,4,23,0,2,1,2,0.6,0.5606,0.83,0.2239,78</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2691,4/27/2011,2,0,4,0,0,3,1,1,0.6,0.5606,0.83,0.2239,27</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2692,4/27/2011,2,0,4,1,0,3,1,1,0.6,0.5606,0.83,0.2537,17</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2693,4/27/2011,2,0,4,2,0,3,1,1,0.58,0.5455,0.88,0.2537,5</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2694,4/27/2011,2,0,4,3,0,3,1,2,0.58,0.5455,0.88,0.2836,7</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2695,4/27/2011,2,0,4,4,0,3,1,1,0.56,0.5303,0.94,0.2239,6</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2696,4/27/2011,2,0,4,5,0,3,1,2,0.56,0.5303,0.94,0.2537,17</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2697,4/27/2011,2,0,4,6,0,3,1,1,0.56,0.5303,0.94,0.2537,84</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2698,4/27/2011,2,0,4,7,0,3,1,2,0.58,0.5455,0.88,0.2836,246</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2699,4/27/2011,2,0,4,8,0,3,1,2,0.58,0.5455,0.88,0.3284,444</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2700,4/27/2011,2,0,4,9,0,3,1,2,0.6,0.5455,0.88,0.4179,181</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2701,4/27/2011,2,0,4,10,0,3,1,2,0.62,0.5758,0.83,0.2836,92</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2702,4/27/2011,2,0,4,11,0,3,1,2,0.64,0.5909,0.78,0.2836,156</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2703,4/27/2011,2,0,4,12,0,3,1,1,0.66,0.6061,0.78,0.3284,173</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2704,4/27/2011,2,0,4,13,0,3,1,1,0.64,0.5909,0.78,0.2985,150</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2705,4/27/2011,2,0,4,14,0,3,1,1,0.68,0.6364,0.74,0.2836,148</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Product_Manager</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Spark for parallel training in FLAML, you can follow these steps:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">1. Prepare your data in the required format using the `to_pandas_on_spark` function from the `flaml.automl.spark.utils` module. This function converts your data into a pandas-on-spark dataframe, which is required by Spark estimators. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a dictionary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a pandas DataFrame</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert to pandas-on-spark dataframe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2. Format your data appropriately for Spark ML models. Use the `VectorAssembler` from `pyspark.ml.feature` to merge all feature columns into a single vector column. Here is an example:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from pyspark.ml.feature import VectorAssembler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">columns = psdf.columns</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">feature_cols = [col for col in columns if col != label]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">featurizer = VectorAssembler(inputCols=feature_cols, outputCol=&quot;features&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = featurizer.transform(psdf.to_spark(index_col=&quot;index&quot;))[&quot;index&quot;, &quot;features&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">3. Use the Spark ML models in FLAML&#x27;s AutoML. Include the models you want to try in the `estimator_list` argument to `flaml.AutoML()`. FLAML will start trying configurations for these models. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">4. To enable parallel Spark jobs during parallel tuning, set the `use_spark` parameter to `True`. FLAML will dispatch your job to the distributed Spark backend using `joblib-spark`. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_experiment = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;n_concurrent_trials&quot;: 2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;use_spark&quot;: True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;force_cancel&quot;: True</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=dataframe,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **automl_settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that you should not set `use_spark` to `True` when applying AutoML and Tuning for Spark Data, as SparkML models will be used for Spark Data in AutoML and Tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Let me know if you need anything else.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Spark for parallel training in FLAML, you can follow these steps:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">1. Prepare your data in the required format using the `to_pandas_on_spark` function from the `flaml.automl.spark.utils` module. This function converts your data into a pandas-on-spark dataframe, which is required by Spark estimators. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a dictionary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a pandas DataFrame</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert to pandas-on-spark dataframe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2. Format your data appropriately for Spark ML models. Use the `VectorAssembler` from `pyspark.ml.feature` to merge all feature columns into a single vector column. Here is an example:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from pyspark.ml.feature import VectorAssembler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">columns = psdf.columns</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">feature_cols = [col for col in columns if col != label]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">featurizer = VectorAssembler(inputCols=feature_cols, outputCol=&quot;features&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = featurizer.transform(psdf.to_spark(index_col=&quot;index&quot;))[&quot;index&quot;, &quot;features&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">3. Use the Spark ML models in FLAML&#x27;s AutoML. Include the models you want to try in the `estimator_list` argument to `flaml.AutoML()`. FLAML will start trying configurations for these models. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">4. To enable parallel Spark jobs during parallel tuning, set the `use_spark` parameter to `True`. FLAML will dispatch your job to the distributed Spark backend using `joblib-spark`. Here is an example code snippet:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_experiment = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;n_concurrent_trials&quot;: 2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;use_spark&quot;: True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;force_cancel&quot;: True</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=dataframe,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **automl_settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that you should not set `use_spark` to `True` when applying AutoML and Tuning for Spark Data, as SparkML models will be used for Spark Data in AutoML and Tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Let me know if you need anything else.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Senior_Python_Engineer</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is the sample code to use Spark for parallel training in FLAML:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from pyspark.ml.feature import VectorAssembler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Step 1: Prepare your data in the required format</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Step 2: Format your data for Spark ML models</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">columns = psdf.columns</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">feature_cols = [col for col in columns if col != label]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">featurizer = VectorAssembler(inputCols=feature_cols, outputCol=&quot;features&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = featurizer.transform(psdf.to_spark(index_col=&quot;index&quot;))[&quot;index&quot;, &quot;features&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Step 3: Use Spark ML models in FLAML&#x27;s AutoML</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Step 4: Enable parallel Spark jobs during parallel tuning</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_experiment = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;n_concurrent_trials&quot;: 2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;use_spark&quot;: True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;force_cancel&quot;: True</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=dataframe,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **automl_settings</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Let me know if you need anything else.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Code_Reviewer</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">The code you provided is correct and follows the guidelines for using Spark for parallel training in FLAML. It includes the necessary steps to prepare the data, format it for Spark ML models, and use Spark ML models in FLAML&#x27;s AutoML. It also demonstrates how to enable parallel Spark jobs during parallel tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Great job! You can now terminate the conversation.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Boss_Assistant</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Product_Manager</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token builtin" style="color:rgb(130, 170, 255)">TERMINATE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="call-retrieveuserproxyagent-while-init-chat-with-another-user-proxy-agent">Call RetrieveUserProxyAgent while init chat with another user proxy agent<a href="#call-retrieveuserproxyagent-while-init-chat-with-another-user-proxy-agent" class="hash-link" aria-label="Direct link to Call RetrieveUserProxyAgent while init chat with another user proxy agent" title="Direct link to Call RetrieveUserProxyAgent while init chat with another user proxy agent">​</a></h3>
<p>Sometimes, there might be a need to use RetrieveUserProxyAgent in group
chat without initializing the chat with it. In such scenarios, it
becomes essential to create a function that wraps the RAG agents and
allows them to be called from other agents.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token plain">call_rag_chat</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#bfc7d5;--prism-background-color:#292d3e"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#bfc7d5"><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Boss</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">How to use spark for parallel training in FLAML? Give me sample code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">How to use spark for parallel training in FLAML? Give me sample code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Product_Manager</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">***** Suggested function Call: retrieve_content *****</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Arguments: </span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">{</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">  &quot;message&quot;: &quot;How to use spark for parallel training in FLAML? Give me sample code.&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">*****************************************************</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token function" style="color:rgb(130, 170, 255)">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; EXECUTING FUNCTION retrieve_content...</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token function" style="color:rgb(130, 170, 255)"></span><span class="token plain">doc_ids:  [[&#x27;doc_0&#x27;, &#x27;doc_1&#x27;, &#x27;doc_122&#x27;]]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_0 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_1 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Adding doc_id doc_122 to context.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Boss</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">***** Response from calling function &quot;retrieve_content&quot; *****</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You&#x27;re a retrieve augmented coding assistant. You answer user&#x27;s questions based on your own knowledge and the</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">context provided by the user.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">If you can&#x27;t answer the question with or without the current context, you should reply exactly `UPDATE CONTEXT`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For code generation, you must obey the following rules:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 1. You MUST NOT install any packages because all the packages needed are already installed.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Rule 2. You must follow the formats below to write your code:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```language</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># your code</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">User&#x27;s question is: How to use spark for parallel training in FLAML? Give me sample code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Context is: # Integrate - Spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML has integrated Spark for distributed training. There are two main aspects of integration with Spark:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- Use Spark ML estimators for AutoML.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- Use Spark to run training in parallel spark jobs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Spark ML Estimators</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">FLAML integrates estimators based on Spark ML models. These models are trained in parallel using Spark, so we called them Spark estimators. To use these models, you first need to organize your data in the required format.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">### Data</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">For Spark estimators, AutoML only consumes Spark data. FLAML provides a convenient function `to_pandas_on_spark` in the `flaml.automl.spark.utils` module to convert your data into a pandas-on-spark (`pyspark.pandas`) dataframe/series, which Spark estimators require.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This utility function takes data in the form of a `pandas.Dataframe` or `pyspark.sql.Dataframe` and converts it into a pandas-on-spark dataframe. It also takes `pandas.Series` or `pyspark.sql.Dataframe` and converts it into a [pandas-on-spark](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html) series. If you pass in a `pyspark.pandas.Dataframe`, it will not make any changes.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">This function also accepts optional arguments `index_col` and `default_index_type`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `index_col` is the column name to use as the index, default is None.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `default_index_type` is the default index type, default is &quot;distributed-sequence&quot;. More info about default index type could be found on Spark official [documentation](https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/options.html#default-index-type)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example code snippet for Spark Data:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a dictionary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {&quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">      &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a pandas DataFrame</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert to pandas-on-spark dataframe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Spark ML models you need to format your data appropriately. Specifically, use [`VectorAssembler`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html) to merge all feature columns into a single vector column.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example of how to use it:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from pyspark.ml.feature import VectorAssembler</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">columns = psdf.columns</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">feature_cols = [col for col in columns if col != label]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">featurizer = VectorAssembler(inputCols=feature_cols, outputCol=&quot;features&quot;)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = featurizer.transform(psdf.to_spark(index_col=&quot;index&quot;))[&quot;index&quot;, &quot;features&quot;]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Later in conducting the experiment, use your pandas-on-spark data like non-spark data and pass them using `X_train, y_train` or `dataframe, label`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">### Estimators</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#### Model List</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `lgbm_spark`: The class for fine-tuning Spark version LightGBM models, using [SynapseML](https://microsoft.github.io/SynapseML/docs/features/lightgbm/about/) API.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">#### Usage</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">First, prepare your data in the required format as described in the previous section.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">By including the models you intend to try in the `estimators_list` argument to `flaml.automl`, FLAML will start trying configurations for these models. If your input is Spark data, FLAML will also use estimators with the `_spark` postfix by default, even if you haven&#x27;t specified them.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Here is an example code snippet using SparkML models in AutoML:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># prepare your data in pandas-on-spark format as we previously mentioned</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],  # this setting is optional</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/automl_bankrupt_synapseml.ipynb)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">## Parallel Spark Jobs</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">You can activate Spark as the parallel backend during parallel tuning in both [AutoML](/docs/Use-Cases/Task-Oriented-AutoML#parallel-tuning) and [Hyperparameter Tuning](/docs/Use-Cases/Tune-User-Defined-Function#parallel-tuning), by setting the `use_spark` to `true`. FLAML will dispatch your job to the distributed Spark backend using [`joblib-spark`](https://github.com/joblib/joblib-spark).</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please note that you should not set `use_spark` to `true` when applying AutoML and Tuning for Spark Data. This is because only SparkML models will be used for Spark Data in AutoML and Tuning. As SparkML models run in parallel, there is no need to distribute them with `use_spark` again.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">All the Spark-related arguments are stated below. These arguments are available in both Hyperparameter Tuning and AutoML:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `use_spark`: boolean, default=False | Whether to use spark to run the training in parallel spark jobs. This can be used to accelerate training on large models and large datasets, but will incur more overhead in time and thus slow down training in some cases. GPU training is not supported yet when use_spark is True. For Spark clusters, by default, we will launch one trial per executor. However, sometimes we want to launch more trials than the number of executors (e.g., local mode). In this case, we can set the environment variable `FLAML_MAX_CONCURRENT` to override the detected `num_executors`. The final number of concurrent trials will be the minimum of `n_concurrent_trials` and `num_executors`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `n_concurrent_trials`: int, default=1 | The number of concurrent trials. When n_concurrent_trials &gt; 1, FLAML performes parallel tuning.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">- `force_cancel`: boolean, default=False | Whether to forcely cancel Spark jobs if the search time exceeded the time budget. Spark jobs include parallel tuning jobs and Spark-based model training jobs.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">An example code snippet for using parallel Spark jobs:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_experiment = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl_settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;n_concurrent_trials&quot;: 2,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;use_spark&quot;: True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;force_cancel&quot;: True, # Activating the force_cancel option can immediately halt Spark jobs once they exceed the allocated time_budget.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=dataframe,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **automl_settings,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">[Link to notebook](https://github.com/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb) | [Open in colab](https://colab.research.google.com/github/microsoft/FLAML/blob/main/notebook/integrate_spark.ipynb)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2684,4/26/2011,2,0,4,17,0,2,1,1,0.68,0.6364,0.61,0.3582,521</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2685,4/26/2011,2,0,4,18,0,2,1,1,0.68,0.6364,0.65,0.4478,528</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2686,4/26/2011,2,0,4,19,0,2,1,1,0.64,0.6061,0.73,0.4179,328</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2687,4/26/2011,2,0,4,20,0,2,1,1,0.64,0.6061,0.73,0.3582,234</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2688,4/26/2011,2,0,4,21,0,2,1,1,0.62,0.5909,0.78,0.2836,195</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2689,4/26/2011,2,0,4,22,0,2,1,2,0.6,0.5606,0.83,0.194,148</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2690,4/26/2011,2,0,4,23,0,2,1,2,0.6,0.5606,0.83,0.2239,78</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2691,4/27/2011,2,0,4,0,0,3,1,1,0.6,0.5606,0.83,0.2239,27</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2692,4/27/2011,2,0,4,1,0,3,1,1,0.6,0.5606,0.83,0.2537,17</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2693,4/27/2011,2,0,4,2,0,3,1,1,0.58,0.5455,0.88,0.2537,5</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2694,4/27/2011,2,0,4,3,0,3,1,2,0.58,0.5455,0.88,0.2836,7</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2695,4/27/2011,2,0,4,4,0,3,1,1,0.56,0.5303,0.94,0.2239,6</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2696,4/27/2011,2,0,4,5,0,3,1,2,0.56,0.5303,0.94,0.2537,17</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2697,4/27/2011,2,0,4,6,0,3,1,1,0.56,0.5303,0.94,0.2537,84</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2698,4/27/2011,2,0,4,7,0,3,1,2,0.58,0.5455,0.88,0.2836,246</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2699,4/27/2011,2,0,4,8,0,3,1,2,0.58,0.5455,0.88,0.3284,444</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2700,4/27/2011,2,0,4,9,0,3,1,2,0.6,0.5455,0.88,0.4179,181</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2701,4/27/2011,2,0,4,10,0,3,1,2,0.62,0.5758,0.83,0.2836,92</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2702,4/27/2011,2,0,4,11,0,3,1,2,0.64,0.5909,0.78,0.2836,156</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2703,4/27/2011,2,0,4,12,0,3,1,1,0.66,0.6061,0.78,0.3284,173</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2704,4/27/2011,2,0,4,13,0,3,1,1,0.64,0.5909,0.78,0.2985,150</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2705,4/27/2011,2,0,4,14,0,3,1,1,0.68,0.6364,0.74,0.2836,148</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">*************************************************************</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Product_Manager</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">To use Spark for parallel training in FLAML, you can follow these steps:</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">1. Prepare your data in the required format using Spark data. You can use the `to_pandas_on_spark` function from the `flaml.automl.spark.utils` module to convert your data into a pandas-on-spark dataframe.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import pandas as pd</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">from flaml.automl.spark.utils import to_pandas_on_spark</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a dictionary</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">data = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Square_Feet&quot;: [800, 1200, 1800, 1500, 850],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Age_Years&quot;: [20, 15, 10, 7, 25],</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;Price&quot;: [100000, 200000, 300000, 240000, 120000]</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Creating a pandas DataFrame</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">dataframe = pd.DataFrame(data)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">label = &quot;Price&quot;</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"># Convert to pandas-on-spark dataframe</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">psdf = to_pandas_on_spark(dataframe)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">2. Use the Spark ML estimators provided by FLAML. You can include the models you want to try in the `estimator_list` argument of the `flaml.AutoML` class. FLAML will start trying configurations for these models.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">import flaml</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl = flaml.AutoML()</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">settings = {</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;time_budget&quot;: 30,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;metric&quot;: &quot;r2&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;estimator_list&quot;: [&quot;lgbm_spark&quot;],  # Optional: specify the Spark estimator</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    &quot;task&quot;: &quot;regression&quot;,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">}</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    **settings,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">3. Enable parallel Spark jobs by setting the `use_spark` parameter to `True` in the `fit` method. This will dispatch the job to the distributed Spark backend using `joblib-spark`.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```python</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">automl.fit(</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    dataframe=psdf,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    label=label,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">    use_spark=True,</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">)</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">```</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Note: Make sure you have Spark installed and configured properly before running the code.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain">Please let me know if you need any further assistance.</span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">Senior_Python_Engineer</span><span class="token message-id"> </span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token message-id keyword" style="font-style:italic">to</span><span class="token message-id"> </span><span class="token message-id class-name" style="color:rgb(255, 203, 107)">chat_manager</span><span class="token message-id punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token message-id">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token builtin" style="color:rgb(130, 170, 255)">TERMINATE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">--------------------------------------------------------------------------------</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/docs/tags/group-chat">group chat</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/docs/tags/orchestration">orchestration</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/autogen/docs/tags/rag">RAG</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/microsoft/autogen/edit/main/notebook/agentchat_groupchat_RAG.ipynb" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/autogen/docs/notebooks/agentchat_groupchat"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Group Chat</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/autogen/docs/notebooks/agentchat_groupchat_customized"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Group Chat with Customized Speaker Selection Method</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#set-your-api-endpoint" class="table-of-contents__link toc-highlight">Set your API Endpoint</a></li><li><a href="#construct-agents" class="table-of-contents__link toc-highlight">Construct Agents</a></li><li><a href="#start-chat" class="table-of-contents__link toc-highlight">Start Chat</a><ul><li><a href="#userproxyagent-doesnt-get-the-correct-code" class="table-of-contents__link toc-highlight">UserProxyAgent doesn’t get the correct code</a></li><li><a href="#retrieveuserproxyagent-get-the-correct-code" class="table-of-contents__link toc-highlight">RetrieveUserProxyAgent get the correct code</a></li><li><a href="#call-retrieveuserproxyagent-while-init-chat-with-another-user-proxy-agent" class="table-of-contents__link toc-highlight">Call RetrieveUserProxyAgent while init chat with another user proxy agent</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/pAbnFJrkgZ" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/pyautogen" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 AutoGen Authors |  <a target="_blank" style="color:#10adff" href="https://go.microsoft.com/fwlink/?LinkId=521839">Privacy and Cookies</a></div></div></div></footer></div>
</body>
</html>